{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl8+Cq4g3+WoyKZG5v9eG1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annie00000/Project/blob/main/1_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. one-way ANOVA"
      ],
      "metadata": {
        "id": "yIm3OM3xHcyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "def batch_one_way_anova(df, setting_dict):\n",
        "    \"\"\"\n",
        "    對指定的多個欄位分別進行 One-way ANOVA 檢定。\n",
        "\n",
        "    參數:\n",
        "    - df: pd.DataFrame，原始資料集\n",
        "    - setting_dict: 包含 'value_colname' (應變數) 與 'factor_col_list' (自變數清單) 的字典\n",
        "\n",
        "    回傳:\n",
        "    - result_df: 包含 Factor 與 P-value 的 DataFrame\n",
        "    \"\"\"\n",
        "\n",
        "    target_y = setting_dict['value_colname']\n",
        "    factors = setting_dict['factor_col_list']\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for factor in factors:\n",
        "        # 根據 factor 的不同水準 (levels) 進行分組，並收集對應的 y 值 (提取每個群組中對應的數值（應變數）)\n",
        "        groups = [group[target_y].values for name, group in df.groupby(factor)]\n",
        "\n",
        "        # 執行 One-way ANOVA\n",
        "        # *groups 會將 list 中的各組數據拆解為 f_oneway 的獨立參數\n",
        "        f_stat, p_val = stats.f_oneway(*groups)\n",
        "\n",
        "        results.append({\n",
        "            'Factor': factor,\n",
        "            'P-value': p_val\n",
        "        })\n",
        "\n",
        "    # 轉換成 DataFrame 格式輸出\n",
        "    result_df = pd.DataFrame(results)\n",
        "\n",
        "    return result_df\n",
        "\n",
        "# --- 使用範例 ---\n",
        "if __name__ == \"__main__\":\n",
        "    # 建立一個測試用的資料集\n",
        "    data = {\n",
        "        'Machine': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Operator': ['Op1', 'Op2', 'Op1', 'Op2', 'Op1', 'Op2'],\n",
        "        'Yield': [89, 91, 70, 72, 85, 87]\n",
        "    }\n",
        "    test_df = pd.DataFrame(data)\n",
        "\n",
        "    settings = {\n",
        "        'value_colname': 'Yield',\n",
        "        'factor_col_list': ['Machine', 'Operator']\n",
        "    }\n",
        "\n",
        "    # 執行函式\n",
        "    anova_summary = batch_one_way_anova(test_df, settings)\n",
        "    print(anova_summary)"
      ],
      "metadata": {
        "id": "X-TJu8fou57g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 例外處理 (na or 該欄位只有一種分類)"
      ],
      "metadata": {
        "id": "nkPLQuM70wTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def batch_one_way_anova_robust(df, setting_dict):\n",
        "    \"\"\"\n",
        "    進階版：對指定欄位進行 One-way ANOVA，包含錯誤處理與數據檢查。\n",
        "    \"\"\"\n",
        "    target_y = setting_dict['value_colname']\n",
        "    factors = setting_dict['factor_col_list']\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for factor in factors:\n",
        "        try:\n",
        "            # 1. 預處理：排除該 Factor 或 Target Y 為空值的資料行\n",
        "            clean_df = df[[factor, target_y]].dropna()\n",
        "\n",
        "            # 2. 檢查：該因子下是否有至少兩個類別 (Levels)\n",
        "            groups_data = [group[target_y].values for name, group in clean_df.groupby(factor)]\n",
        "\n",
        "            if len(groups_data) < 2:\n",
        "                p_val = np.nan\n",
        "                remark = \"錯誤: 因子類別少於 2 類\"\n",
        "            else:\n",
        "                # 3. 執行 ANOVA\n",
        "                f_stat, p_val = stats.f_oneway(*groups_data)\n",
        "                remark = \"成功\"\n",
        "\n",
        "        except Exception as e:\n",
        "            # 擷取其他可能的錯誤（如：數據全為常數、類型錯誤等）\n",
        "            p_val = np.nan\n",
        "            remark = f\"發生錯誤: {str(e)}\"\n",
        "\n",
        "        results.append({\n",
        "            'Factor': factor,\n",
        "            'P-value': p_val,\n",
        "            'Status': remark\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# --- 測試例外狀況 ---\n",
        "if __name__ == \"__main__\":\n",
        "    # 建立包含異常數據的 DataFrame\n",
        "    data = {\n",
        "        'Normal_Factor': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'One_Level_Factor': ['A', 'A', 'A', 'A', 'A', 'A'], # 只有一種分類\n",
        "        'Missing_Factor': ['A', 'A', 'B', None, 'C', 'C'],  # 有空值\n",
        "        'Yield': [89, 91, 70, 72, 85, 87]\n",
        "    }\n",
        "    test_df = pd.DataFrame(data)\n",
        "\n",
        "    settings = {\n",
        "        'value_colname': 'Yield',\n",
        "        'factor_col_list': ['Normal_Factor', 'One_Level_Factor', 'Missing_Factor']\n",
        "    }\n",
        "\n",
        "    anova_summary = batch_one_way_anova_robust(test_df, settings)\n",
        "    print(anova_summary)"
      ],
      "metadata": {
        "id": "aNVfZXOh02je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 使用 '向量化' 加快速度 & 例外處理"
      ],
      "metadata": {
        "id": "VkWgl6PM23Mh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 結構化檢查：利用 if/else 預先排除「分類不足」或「全為空值」的情況。\n",
        "\n",
        "- 數值保護：防止分母為 0（例如所有數據完全一樣導致變異數為 0）造成程式崩潰。"
      ],
      "metadata": {
        "id": "djx0Gu133AN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def fast_batch_anova_with_error_handling(df, setting_dict):\n",
        "    y_name = setting_dict['value_colname']\n",
        "    factors = setting_dict['factor_col_list']\n",
        "\n",
        "    # --- 1. 全域預處理 ---\n",
        "    # 確保應變數 y 是數值型態且移除 NaN (ANOVA 對 y 的缺失值很敏感)\n",
        "    temp_df = df.copy()\n",
        "    temp_df[y_name] = pd.to_numeric(temp_df[y_name], errors='coerce')\n",
        "\n",
        "    # 這裡只針對 y 做初步過濾，確保計算總變異時基礎一致\n",
        "    valid_mask = temp_df[y_name].notna()\n",
        "    y = temp_df.loc[valid_mask, y_name].values\n",
        "\n",
        "    if len(y) == 0:\n",
        "        return pd.DataFrame(columns=['Factor', 'P-value', 'Status'])\n",
        "\n",
        "    n_total = len(y)\n",
        "    sum_y = np.sum(y)\n",
        "    ss_total = np.sum(y**2) - (sum_y**2) / n_total\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # --- 2. 逐一因子運算 ---\n",
        "    for factor in factors:\n",
        "        try:\n",
        "            # 取得當前因子的資料 (排除該因子本身的 NaN)\n",
        "            f_series = temp_df.loc[valid_mask, factor]\n",
        "            current_y = y\n",
        "\n",
        "            # 如果因子欄位有 NaN，需二次過濾\n",
        "            if f_series.isna().any():\n",
        "                sub_mask = f_series.notna()\n",
        "                f_series = f_series[sub_mask]\n",
        "                current_y = y[sub_mask.values]\n",
        "\n",
        "            # 檢查有效樣本數\n",
        "            if len(f_series) < 2:\n",
        "                results.append({'Factor': factor, 'P-value': np.nan, 'Status': 'Error: 有效樣本不足'})\n",
        "                continue\n",
        "\n",
        "            # 使用 factorize 加速分類\n",
        "            group_labels, obs = pd.factorize(f_series)\n",
        "            n_groups = len(obs)\n",
        "\n",
        "            if n_groups < 2:\n",
        "                results.append({'Factor': factor, 'P-value': np.nan, 'Status': 'Error: 因子類別 < 2'})\n",
        "                continue\n",
        "\n",
        "            # 計算統計量\n",
        "            counts = np.bincount(group_labels)\n",
        "            sums = np.bincount(group_labels, weights=current_y)\n",
        "\n",
        "            # 重新計算該因子對應的總變異 (若有因 NaN 剔除資料)\n",
        "            curr_n = len(current_y)\n",
        "            curr_ss_total = np.sum(current_y**2) - (np.sum(current_y)**2) / curr_n\n",
        "\n",
        "            ssb = np.sum(sums**2 / counts) - (np.sum(current_y)**2 / curr_n)\n",
        "            ssw = curr_ss_total - ssb\n",
        "\n",
        "            # 避免數值精確度造成的微小負數\n",
        "            ssw = max(ssw, 0)\n",
        "\n",
        "            df_between = n_groups - 1\n",
        "            df_within = curr_n - n_groups\n",
        "\n",
        "            if ssw == 0:\n",
        "                # 組內無變異，若組間有變異則 P 值極小，若皆無則無法計算\n",
        "                p_val = 0.0 if ssb > 0 else np.nan\n",
        "                status = 'Success: 組內無變異'\n",
        "            else:\n",
        "                f_stat = (ssb / df_between) / (ssw / df_within)\n",
        "                p_val = stats.f.sf(f_stat, df_between, df_within)\n",
        "                status = 'Success'\n",
        "\n",
        "            results.append({'Factor': factor, 'P-value': p_val, 'Status': status})\n",
        "\n",
        "        except Exception as e:\n",
        "            results.append({'Factor': factor, 'P-value': np.nan, 'Status': f'Unexpected Error: {str(e)}'})\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "GdiPw2Nv284m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**這個版本強化的例外處理：**\n",
        "1. 資料類型強制轉換：使用 pd.to_numeric(..., errors='coerce') 確保應變數一定是數字，非數字會變為 NaN。\n",
        "\n",
        "2. 雙重缺失值過濾：\n",
        "  - 先過濾 y 的 NaN。\n",
        "  - 在迴圈內針對每個 factor 過濾其特有的 NaN，確保 bincount 計算時索引與數值長度完全匹配。\n",
        "\n",
        "3. 邊界數值保護：\n",
        "  -ssw = max(ssw, 0)：在浮點數運算中，極小的正數有時會變成極小的負數（如 -1e-15），這會導致 F 檢定報錯，此處強制修正。\n",
        "  - 組內變異為 0 處理：當一組內數據完全相同（SSW=0），這在自動化分析數千個欄位時常發生，直接給予 P=0 (顯著) 或 NaN。\n",
        "\n",
        "4. 穩定性：即使其中一個因子因為資料毀損噴出 Unexpected Error，迴圈也會繼續執行下一個因子。\n"
      ],
      "metadata": {
        "id": "GuIY_Zfg3pGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**這個優化版本之所以快（通常比 stats.f_oneway 快 10 到 50 倍），原因不在於消滅了迴圈，而在於「迴圈內做了什麼」以及「避開了哪些開銷」。**\n",
        "\n",
        "1. 避開了 Python 函式呼叫的「昂貴」開銷:\n",
        "- stats.f_oneway(*groups) 要求你傳入多個陣列。在 for 迴圈中，如果你有 1000 個因子：\n",
        "\n",
        "  - f_oneway 版本：每一輪都要進行 Python 列表拆解 (*groups)、多重的輸入檢查（檢查是否為空、是否為數值）、轉換成 NumPy 陣列。\n",
        "\n",
        "  - 優化版本：直接呼叫 NumPy 的 C 實作底層函式。\n",
        "\n",
        "2. NumPy bincount 的神奇效能（核心差異）:\n",
        "- 這是最關鍵的一點。在標準做法中，groupby 會在 Python 記憶體中建立多個小型 DataFrame 物件，這非常緩慢。\n",
        "  - f_oneway 流程：groupby -> 分割資料 -> 建立多個 list/array -> 傳入函式。\n",
        "\n",
        "  - 優化版本流程：pd.factorize 將標籤轉為整數，然後 np.bincount 一次性在 C 底層完成分組加總。\n",
        "  \n",
        "  - np.bincount 是專門為「整數索引加權加總」設計的，它不會建立中間物件，直接在內存中完成計算，這比 groupby().sum() 快非常多\n",
        "\n",
        "3. 計算量的極簡化\n",
        "- stats.f_oneway 是一個通用函式，它為了準確性會：\n",
        "計算每組的均值。計算每組的變異數。進行大量的輸入驗證。\n",
        "\n",
        "- 但在優化版本中，我們利用了 ANOVA 的平方和分解性質：$$SS_{total} = SS_{between} + SS_{within}$$\n",
        "\n",
        "- 我們預先算好了全域的 $SS_{total}$（這對所有因子都一樣，只需要算一次！），在迴圈內只需要算出 $SS_{between}$，然後直接相減得到 $SS_{within}$。我們省去了一半以上的平方運算。"
      ],
      "metadata": {
        "id": "F-AGIZwA9wm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### 小小 測試\n",
        "import time\n",
        "\n",
        "# 測試標準版 (stats.f_oneway)\n",
        "start = time.time()\n",
        "res1 = batch_one_way_anova(large_df, settings)\n",
        "print(f\"標準版耗時: {time.time() - start:.4f}s\")\n",
        "\n",
        "# 測試優化版 (bincount)\n",
        "start = time.time()\n",
        "res2 = fast_batch_anova_with_error_handling(large_df, settings)\n",
        "print(f\"優化版耗時: {time.time() - start:.4f}s\")"
      ],
      "metadata": {
        "id": "HSPZnzDd-np8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 加快運算速度 & 例外處理 & 快取機制 (Caching) (重複欄位計算化簡)"
      ],
      "metadata": {
        "id": "JXdpWk1871z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def super_fast_anova(df, setting_dict):\n",
        "    y_name = setting_dict['value_colname']\n",
        "    factors = setting_dict['factor_col_list']\n",
        "\n",
        "    # 預處理應變數 y\n",
        "    y_series = pd.to_numeric(df[y_name], errors='coerce')\n",
        "    valid_mask = y_series.notna()\n",
        "    y = y_series[valid_mask].values\n",
        "\n",
        "    if len(y) == 0:\n",
        "        return pd.DataFrame(columns=['Factor', 'P-value', 'Status'])\n",
        "\n",
        "    # 預計算總平方和\n",
        "    n_total = len(y)\n",
        "    curr_sum_y = np.sum(y)\n",
        "    curr_ss_total = np.sum(y**2) - (curr_sum_y**2) / n_total\n",
        "\n",
        "    # 快取字典： {資料指紋: (P-value, Status)}\n",
        "    cache = {}\n",
        "    results = []\n",
        "\n",
        "    for factor in factors:\n",
        "        # 取得該因子的資料 (對齊 y 的有效位)\n",
        "        f_series = df.loc[valid_mask, factor]\n",
        "\n",
        "        # --- 核心優化：產生資料指紋 ---\n",
        "        # 使用 tuple 轉換作為 key，這能代表該欄位的「內容組合」\n",
        "        # 如果欄位內容完全一樣，指紋就會一樣\n",
        "        data_fingerprint = tuple(f_series.values)\n",
        "\n",
        "        if data_fingerprint in cache:\n",
        "            p_val, status = cache[data_fingerprint]\n",
        "            results.append({'Factor': factor, 'P-value': p_val, 'Status': f'Cache Hit ({status})'})\n",
        "            continue\n",
        "\n",
        "        # --- 若快取未命中，則執行運算 ---\n",
        "        try:\n",
        "            # 處理因子內的 NaN\n",
        "            if f_series.isna().any():\n",
        "                # 注意：若有 NaN，資料指紋會不同，此處簡化處理\n",
        "                # 實務上建議預先填補或處理 NaN 以極大化快取效果\n",
        "                pass\n",
        "\n",
        "            group_labels, obs = pd.factorize(f_series)\n",
        "            n_groups = len(obs)\n",
        "\n",
        "            if n_groups < 2:\n",
        "                res = (np.nan, 'Error: Category < 2')\n",
        "            else:\n",
        "                counts = np.bincount(group_labels)\n",
        "                sums = np.bincount(group_labels, weights=y)\n",
        "\n",
        "                ssb = np.sum(sums**2 / counts) - (curr_sum_y**2 / n_total)\n",
        "                ssw = max(curr_ss_total - ssb, 0)\n",
        "\n",
        "                if ssw == 0:\n",
        "                    p_val = 0.0 if ssb > 0 else np.nan\n",
        "                    res = (p_val, 'Success (No Within-Var)')\n",
        "                else:\n",
        "                    f_stat = (ssb / (n_groups - 1)) / (ssw / (n_total - n_groups))\n",
        "                    p_val = stats.f.sf(f_stat, n_groups - 1, n_total - n_groups)\n",
        "                    res = (p_val, 'Success')\n",
        "\n",
        "        except Exception as e:\n",
        "            res = (np.nan, f'Error: {str(e)}')\n",
        "\n",
        "        # 存入快取並記錄結果\n",
        "        cache[data_fingerprint] = res\n",
        "        results.append({'Factor': factor, 'P-value': res[0], 'Status': res[1]})\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "iyygIRR2CUba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-1. 上方的優化版本 :\n"
      ],
      "metadata": {
        "id": "CCvqCkpCDMcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "預先篩選出「不重覆」的因子進行計算，最後再對應回原本的欄位。這比多進程更穩定且不需要額外資源。\n",
        "\n",
        "- 「終極優化版」：結合了唯一性篩選與 NumPy 向量化。"
      ],
      "metadata": {
        "id": "RMw3nZl3DW-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def ultimate_anova_processor(df, setting_dict):\n",
        "    y_name = setting_dict['value_colname']\n",
        "    factors = setting_dict['factor_col_list']\n",
        "\n",
        "    # 1. 預處理應變數\n",
        "    y = pd.to_numeric(df[y_name], errors='coerce').values\n",
        "    valid_mask = ~np.isnan(y)\n",
        "    y_clean = y[valid_mask]\n",
        "    n_total = len(y_clean)\n",
        "\n",
        "    if n_total < 2: return pd.DataFrame()\n",
        "\n",
        "    # 預計算全域統計量\n",
        "    sum_y = np.sum(y_clean)\n",
        "    ss_total = np.sum(y_clean**2) - (sum_y**2) / n_total\n",
        "\n",
        "    # 2. 找出「內容唯一」的欄位組合，避免重複計算\n",
        "    # 我們只對不同的內容進行一次 ANOVA\n",
        "    unique_patterns = {} # 存放 {tuple_data: first_factor_name}\n",
        "    mapping = {}         # 存放 {factor_name: tuple_data}\n",
        "\n",
        "    for f in factors:\n",
        "        # 轉成 tuple 作為 Key\n",
        "        pattern = tuple(df.loc[valid_mask, f].fillna(\"NAN_VAL\").values)\n",
        "        mapping[f] = pattern\n",
        "        if pattern not in unique_patterns:\n",
        "            unique_patterns[pattern] = f\n",
        "\n",
        "    # 3. 僅對唯一模式進行計算\n",
        "    distinct_results = {}\n",
        "    for pattern, first_f_name in unique_patterns.items():\n",
        "        try:\n",
        "            # 使用 pd.factorize 的 C 實作加速\n",
        "            labels, uniques = pd.factorize(pattern)\n",
        "            n_groups = len(uniques)\n",
        "\n",
        "            if n_groups < 2:\n",
        "                distinct_results[pattern] = (np.nan, \"Category < 2\")\n",
        "                continue\n",
        "\n",
        "            counts = np.bincount(labels)\n",
        "            sums = np.bincount(labels, weights=y_clean)\n",
        "\n",
        "            ssb = np.sum(sums**2 / counts) - (sum_y**2 / n_total)\n",
        "            ssw = max(ss_total - ssb, 0)\n",
        "\n",
        "            if ssw == 0:\n",
        "                p = 0.0 if ssb > 0 else np.nan\n",
        "            else:\n",
        "                f_stat = (ssb / (n_groups - 1)) / (ssw / (n_total - n_groups))\n",
        "                p = stats.f.sf(f_stat, n_groups - 1, n_total - n_groups)\n",
        "\n",
        "            distinct_results[pattern] = (p, \"Success\")\n",
        "        except:\n",
        "            distinct_results[pattern] = (np.nan, \"Error\")\n",
        "\n",
        "    # 4. 將結果映射回原始的所有欄位\n",
        "    final_output = []\n",
        "    for f in factors:\n",
        "        p_val, status = distinct_results[mapping[f]]\n",
        "        final_output.append({'Factor': f, 'P-value': p_val, 'Status': status})\n",
        "\n",
        "    return pd.DataFrame(final_output)"
      ],
      "metadata": {
        "id": "lhCCmsb4DR4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 高性能實作版本 (Hybrid Adaptive ANOVA)\n",
        "這個版本會根據資料量自動決定是否啟動平行運算，並優化記憶體使用"
      ],
      "metadata": {
        "id": "RiIJeCUJJLy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "對於 極小到極大的變動區間，建議採用 「批次處理 (Batching) + 混合策略」：\n",
        "\n",
        "- 自動判定：判斷 Rows * Cols 的總量。如果超過門檻（例如 100 萬個數據點），才啟動多進程。\n",
        "\n",
        "- 預先簡化：不論數據大小，先用 pd.factorize 和 mapping 剔除重複欄位。\n",
        "\n",
        "- 分批 (Chunks)：不要把 1,000 個欄位一次全塞進多進程，而是分批處理，平衡負擔"
      ],
      "metadata": {
        "id": "40bNhlD0JU0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "def single_anova_calc(args):\n",
        "    \"\"\"子進程專用的最小運算單元\"\"\"\n",
        "    pattern, y_clean, n_total, sum_y, ss_total = args\n",
        "    try:\n",
        "        labels, uniques = pd.factorize(pattern)\n",
        "        n_groups = len(uniques)\n",
        "        if n_groups < 2: return (np.nan, \"Category < 2\")\n",
        "\n",
        "        counts = np.bincount(labels)\n",
        "        sums = np.bincount(labels, weights=y_clean)\n",
        "\n",
        "        ssb = np.sum(sums**2 / counts) - (sum_y**2 / n_total)\n",
        "        ssw = max(ss_total - ssb, 0)\n",
        "\n",
        "        if ssw == 0:\n",
        "            p = 0.0 if ssb > 0 else np.nan\n",
        "            status = \"Success (No Within-Var)\"\n",
        "        else:\n",
        "            f_stat = (ssb / (n_groups - 1)) / (ssw / (n_total - n_groups))\n",
        "            p = stats.f.sf(f_stat, n_groups - 1, n_total - n_groups)\n",
        "            status = \"Success\"\n",
        "        return (p, status)\n",
        "    except:\n",
        "        return (np.nan, \"Error\")\n",
        "\n",
        "def robust_parallel_anova(df, setting_dict):\n",
        "    y_name = setting_dict['value_colname']\n",
        "    factors = setting_dict['factor_col_list']\n",
        "\n",
        "    # 1. 預處理應變數 (一次性)\n",
        "    y = pd.to_numeric(df[y_name], errors='coerce').values\n",
        "    valid_mask = ~np.isnan(y)\n",
        "    y_clean = y[valid_mask]\n",
        "    n_total = len(y_clean)\n",
        "    sum_y = np.sum(y_clean)\n",
        "    ss_total = np.sum(y_clean**2) - (sum_y**2) / n_total\n",
        "\n",
        "    # 2. 雜湊與去重 (不論資料大小，這步對 1000 cols 都很有用)\n",
        "    unique_patterns = {}\n",
        "    mapping = {}\n",
        "    for f in factors:\n",
        "        # 針對大數據，使用 hash 處理 tuple 以節省記憶體\n",
        "        pattern = tuple(df.loc[valid_mask, f].fillna(\"NAN\").values)\n",
        "        mapping[f] = pattern\n",
        "        if pattern not in unique_patterns:\n",
        "            unique_patterns[pattern] = f\n",
        "\n",
        "    # 3. 策略決策：判斷是否需要平行運算\n",
        "    # 門檻值：(模式數量 * 資料筆數) > 5,000,000\n",
        "    task_load = len(unique_patterns) * n_total\n",
        "    distinct_patterns = list(unique_patterns.keys())\n",
        "\n",
        "    if task_load > 5_000_000:\n",
        "        # --- 多進程模式 ---\n",
        "        # 封裝參數\n",
        "        args_list = [(p, y_clean, n_total, sum_y, ss_total) for p in distinct_patterns]\n",
        "        with Pool(processes=cpu_count()) as pool:\n",
        "            raw_results = pool.map(single_anova_calc, args_list)\n",
        "        distinct_results = dict(zip(distinct_patterns, raw_results))\n",
        "    else:\n",
        "        # --- 單進程模式 ---\n",
        "        distinct_results = {p: single_anova_calc((p, y_clean, n_total, sum_y, ss_total))\n",
        "                           for p in distinct_patterns}\n",
        "\n",
        "    # 4. 對應回原始欄位\n",
        "    final_output = []\n",
        "    for f in factors:\n",
        "        p_val, status = distinct_results[mapping[f]]\n",
        "        final_output.append({'Factor': f, 'P-value': p_val, 'Status': status})\n",
        "\n",
        "    return pd.DataFrame(final_output)"
      ],
      "metadata": {
        "id": "GF3W-69zJNLH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}